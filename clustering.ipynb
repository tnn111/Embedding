{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c51220",
   "metadata": {},
   "outputs": [],
   "source": "import os\nos.environ['KERAS_BACKEND'] = 'jax'\n\nimport numpy as np\nimport keras\nfrom umap import UMAP\nimport hdbscan\nimport matplotlib.pyplot as plt\n\n# Import custom layers needed to load the encoder\nimport sys\nsys.path.insert(0, '.')\nfrom VAE import Sampling, ClipLayer"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63c687",
   "metadata": {},
   "outputs": [],
   "source": "# ========== LOAD DATA ==========\ndata_path = './Data/multimer_frequencies_l5000_shuffled.npy'\ndata = np.load(data_path)\nprint(f'Loaded {len(data)} samples with {data.shape[1]} features')\n\n# Transform to log-space (same as training)\nX = np.log(data.astype(np.float32) + 1e-6)\nprint(f'Log-transformed: Min {X.min():.2f}, Max {X.max():.2f}, Mean {X.mean():.2f}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce553e8",
   "metadata": {},
   "outputs": [],
   "source": "# ========== LOAD ENCODER AND GENERATE EMBEDDINGS ==========\nencoder = keras.models.load_model(\n    'vae_encoder_best.keras',\n    custom_objects = {'Sampling': Sampling, 'ClipLayer': ClipLayer}\n)\nprint('Encoder loaded successfully')\n\n# Get 256-dimensional embeddings (z_mean for deterministic embedding)\nz_mean, z_log_var, z = encoder.predict(X, batch_size = 4096, verbose = 1)\nprint(f'Embeddings shape: {z_mean.shape}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1yvrsdjwo7",
   "metadata": {},
   "outputs": [],
   "source": "# ========== UMAP REDUCTION FOR CLUSTERING ==========\nprint('Running UMAP to 20 dimensions for clustering...')\nreducer_20d = UMAP(\n    n_components = 20,\n    n_neighbors = 15,\n    min_dist = 0.0,\n    metric = 'euclidean',\n    random_state = 42,\n    verbose = True\n)\nembedding_20d = reducer_20d.fit_transform(z_mean)\nprint(f'UMAP 20D embedding shape: {embedding_20d.shape}')\n\n# ========== HDBSCAN CLUSTERING ==========\nprint('Running HDBSCAN clustering...')\nclusterer = hdbscan.HDBSCAN(\n    min_cluster_size = 15,\n    min_samples = None,  # defaults to min_cluster_size\n    metric = 'euclidean',\n    cluster_selection_method = 'eom'\n)\nlabels = clusterer.fit_predict(embedding_20d)\n\nn_clusters = len(set(labels)) - (1 if -1 in labels else 0)\nn_noise = (labels == -1).sum()\nprint(f'Found {n_clusters} clusters')\nprint(f'Noise points: {n_noise} ({100 * n_noise / len(labels):.1f}%)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4dfc06",
   "metadata": {},
   "outputs": [],
   "source": "# ========== UMAP TO 2D FOR VISUALIZATION ==========\nprint('Running UMAP to 2D for visualization...')\nreducer_2d = UMAP(\n    n_components = 2,\n    n_neighbors = 15,\n    min_dist = 0.1,\n    metric = 'euclidean',\n    random_state = 42,\n    verbose = True\n)\nembedding_2d = reducer_2d.fit_transform(z_mean)\nprint(f'UMAP 2D embedding shape: {embedding_2d.shape}')"
  },
  {
   "cell_type": "code",
   "id": "7arh4y35oq",
   "source": "# ========== VISUALIZATION ==========\nfig, ax = plt.subplots(figsize = (12, 10))\n\n# Create colormap - use gray for noise (-1), colors for clusters\nunique_labels = sorted(set(labels))\ncolors = plt.cm.tab20(np.linspace(0, 1, max(20, n_clusters)))\n\n# Plot noise points first (in gray)\nnoise_mask = labels == -1\nif noise_mask.any():\n    ax.scatter(\n        embedding_2d[noise_mask, 0],\n        embedding_2d[noise_mask, 1],\n        c = 'lightgray',\n        s = 1,\n        alpha = 0.3,\n        label = f'Noise ({n_noise})'\n    )\n\n# Plot each cluster\nfor i, cluster_id in enumerate([l for l in unique_labels if l != -1]):\n    mask = labels == cluster_id\n    ax.scatter(\n        embedding_2d[mask, 0],\n        embedding_2d[mask, 1],\n        c = [colors[i % len(colors)]],\n        s = 2,\n        alpha = 0.6,\n        label = f'Cluster {cluster_id} ({mask.sum()})'\n    )\n\nax.set_xlabel('UMAP 1')\nax.set_ylabel('UMAP 2')\nax.set_title(f'VAE Embeddings: {n_clusters} clusters, {n_noise} noise points ({len(labels)} total)')\n\n# Only show legend if not too many clusters\nif n_clusters <= 20:\n    ax.legend(loc = 'best', markerscale = 3, fontsize = 8)\n\nplt.tight_layout()\nplt.savefig('vae_clusters.png', dpi = 300, bbox_inches = 'tight')\nplt.show()\nprint('Saved visualization to vae_clusters.png')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "z998eh97jpb",
   "source": "# ========== SAVE RESULTS ==========\nnp.save('vae_embeddings_256d.npy', z_mean)\nnp.save('umap_embedding_20d.npy', embedding_20d)\nnp.save('umap_embedding_2d.npy', embedding_2d)\nnp.save('cluster_labels.npy', labels)\n\nprint('Saved:')\nprint(f'  vae_embeddings_256d.npy - {z_mean.shape}')\nprint(f'  umap_embedding_20d.npy - {embedding_20d.shape}')\nprint(f'  umap_embedding_2d.npy - {embedding_2d.shape}')\nprint(f'  cluster_labels.npy - {labels.shape}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}